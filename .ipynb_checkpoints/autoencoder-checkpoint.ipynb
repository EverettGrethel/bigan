{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c44b4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495aef96-9947-4968-a7ac-177f81a83dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..\\..\\early-stopping-pytorch')\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70724590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.input_shape = kwargs[\"input_shape\"]\n",
    "        # number of hidden units in first hidden layer\n",
    "        self.n_units = kwargs[\"n_units\"]\n",
    "        self.latent_units = kwargs[\"latent_units\"]\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            # Linear(): Initiate a linear function theta*x + b\n",
    "            nn.Linear(in_features=self.input_shape, out_features=self.n_units),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Linear(in_features=self.n_units, out_features=self.latent_units),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            nn.Linear(in_features=self.latent_units, out_features=self.n_units),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Linear(in_features=self.n_units, out_features=self.input_shape),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    # X denotes features\n",
    "    def forward(self, X):\n",
    "        encode = self.encoder(X)\n",
    "        decode = self.decoder(encode)\n",
    "        return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6b7c31-6d35-4067-ba20-89b11ac6b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoEncoder(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.input_shape = kwargs[\"input_shape\"]\n",
    "        # number of hidden units in first hidden layer\n",
    "        self.n_units = kwargs[\"n_units\"]\n",
    "        # number of hidden units in latent space\n",
    "        self.latent_units = kwargs[\"latent_units\"]\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            nn.Linear(in_features=self.input_shape, out_features=self.n_units),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        # Bottleneck is actually in the encoder, but it must be isolated in order to calculate sparsity\n",
    "        self.bottleneck = torch.nn.Sequential(\n",
    "            nn.Linear(in_features=self.n_units, out_features=self.latent_units),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            nn.Linear(in_features=self.latent_units, out_features=self.n_units),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Linear(in_features=self.n_units, out_features=self.input_shape),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    # X denotes features\n",
    "    def forward(self, X):\n",
    "        encoded = self.encoder(X)\n",
    "        bottleneck = self.bottleneck(encoded)\n",
    "        decoded = self.decoder(bottleneck)\n",
    "        return bottleneck, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca68d50-8eeb-4d3a-8150-f5508bdf9d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data.\n"
     ]
    }
   ],
   "source": [
    "# 10,000 samples, 30x30 matrices\n",
    "is_pca = False\n",
    "data = np.ndarray(shape=(10000,30,30))\n",
    "n_features = data.shape[1] * data.shape[2]\n",
    "\n",
    "for i in range(10000):\n",
    "    path = f'data/jet_matrices/sample{i+1}.dat'\n",
    "    sample = np.loadtxt(path, unpack = True)\n",
    "    data[i] = sample\n",
    "\n",
    "print(\"Done loading data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8891f7fc-06ec-4a54-9e54-3189e67da3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Flatten data and convert to Torch Tensor\n",
    "\n",
    "# 10,000 samples, 900 features\n",
    "X = np.ndarray(shape=(10000, n_features))\n",
    "for i, sample in enumerate(data):\n",
    "    flat = sample.flatten()\n",
    "    X[i] = flat\n",
    "    #print(X[i])\n",
    "\n",
    "# Convert from numpy array to Pytorch tensor\n",
    "X = torch.from_numpy(X)\n",
    "# Convert all scalars to floats. May affect training behavior (ie. reconstructions made of non-binary scalar values)\n",
    "X = X.float()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40435a6-d2d2-4a67-8b9d-a4ceeabda9f9",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38354ca1-cb26-48dc-ad4b-73c616477bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def de_correlate_data(X):\n",
    "    X_pert = np.copy(X)\n",
    "    i = 0\n",
    "    for col in X.T:\n",
    "        #print(col)\n",
    "        X_pert[:,i] = np.random.permutation(col)\n",
    "        #print(X_pert[:,i])\n",
    "        i += 1\n",
    "        \n",
    "    return X_pert\n",
    "\n",
    "# # function demo\n",
    "# z = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "# #z = np.array([[0,1,0],[1,0,1],[1,1,1]])\n",
    "# print(z)\n",
    "# X_pert = de_correlate_data(z)\n",
    "# print(X_pert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d2f802-706f-4e61-b59a-1b5a7c5c11c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot cumulative explained variance w.r.t. number of components\n",
    "\n",
    "def pca_run(X):\n",
    "    pca = PCA(n_components=0.95).fit(X)\n",
    "\n",
    "    #% matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    y = np.cumsum(pca.explained_variance_ratio_)\n",
    "    # n_components = number of components needed to reach cum. variance threshold\n",
    "    n_components = y.size\n",
    "    xi = np.arange(1, n_components+1, step=1)\n",
    "\n",
    "    plt.ylim(0.0,1.1)\n",
    "    plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
    "\n",
    "    plt.xlabel('Number of Components')\n",
    "    #change from 0-based array index to 1-based human-readable label\n",
    "    plt.xticks(np.arange(0, n_components+1, step=1))\n",
    "    plt.ylabel('Cumulative variance (%)')\n",
    "    plt.title('The Number of Components Needed to Explain Variance')\n",
    "\n",
    "    plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "    plt.axhline(y=0.8, color='g', linestyle='-')\n",
    "    plt.axhline(y=0.9, color='b', linestyle='-')\n",
    "    plt.text(0, 0.915, '95% cut-off threshold', color = 'red', fontsize=13)\n",
    "    plt.text(24, 0.85, '90% cut-off threshold', color = 'blue', fontsize=13)\n",
    "    plt.text(12, 0.75, '80% cut-off threshold', color = 'green', fontsize=13)\n",
    "\n",
    "    ax.grid(axis='x')\n",
    "    plt.show()\n",
    "\n",
    "# Run with original data.\n",
    "pca_run(X.numpy())\n",
    "\n",
    "# Run with permutated data.\n",
    "# De-correlates features, so performing worse than original data indicates\n",
    "# existence of correlation in the original data's features.\n",
    "X_pert = de_correlate_data(X)\n",
    "pca_run(X_pert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75306b-57ab-407a-bb35-d7f160e75c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(xi, pca.explained_variance_ratio_, width=0.4)\n",
    "plt.ylabel(\"Percent of Total Variance\")\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.title(\"Significance of Each Principal Component Towards Variance \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96362bf4-42d8-49b8-a6fa-aeb5a8359ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "# Toggle to indicate to training that PCA is in use\n",
    "is_pca = True\n",
    "# -- DEFINE NUMBER OF COMPONENTS HERE --\n",
    "n_components = 5\n",
    "\n",
    "pca = PCA(n_components=n_components).fit(X.numpy())\n",
    "\n",
    "print(X)\n",
    "# If fails, re-run \"Flatten data...\" cell\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca = torch.from_numpy(X_pca)\n",
    "# Convert all scalars to floats. May affect training behavior (ie. reconstructions made of non-binary scalar values)\n",
    "X_pca = X_pca.float()\n",
    "# Replace former n_features with number of components\n",
    "n_features = X_pca.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8875d4ed-f4c5-4bf5-878e-ccb76d4645d7",
   "metadata": {},
   "source": [
    "## Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc40b83a-dcd0-457f-9b37-0261177fb051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# Changes X based on whether PCA was used\n",
    "if is_pca:\n",
    "    X_2 = X_pca\n",
    "else:\n",
    "    X_2 = X\n",
    "\n",
    "batch_size = 32\n",
    "train_size = int(0.8 * len(X_2))\n",
    "val_size = len(X_2) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d9f72fd-043f-4203-ba7e-3098c76b6a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initate data loaders\n",
    "\n",
    "train, val = torch.utils.data.random_split(X_2, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "# Use gpu if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43042c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # USE FOR MNIST ONLY\n",
    "\n",
    "# input_shape = 784\n",
    "# # Convert numpy array to tensor\n",
    "# transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# # Define \n",
    "# train = torchvision.datasets.MNIST(\n",
    "#     root=\"~/torch_datasets\", train=True, transform=transform, download=True\n",
    "# )\n",
    "\n",
    "# test = torchvision.datasets.MNIST(\n",
    "#     root=\"~/torch_datasets\", train=False, transform=transform, download=True\n",
    "# )\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    "# )\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     test, batch_size=batch_size, shuffle=False, num_workers=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e006349d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############################    \n",
    "#   TRAINING & VALIDATION   #\n",
    "#############################\n",
    "\n",
    "class ExceededRangeError(Exception):\n",
    "    \"\"\"Raised when values outside range [0.0, 1.0] are found in BCE loss\"\"\"\n",
    "    pass\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    p = torch.nn.functional.softmax(p, dim=1)\n",
    "    q = torch.nn.functional.softmax(q, dim=1)\n",
    "\n",
    "    s1 = torch.sum(p * torch.log(p / q))\n",
    "    s2 = torch.sum((1 - p) * torch.log((1 - p) / (1 - q)))\n",
    "    s = s1 + s2\n",
    "    return p, q, s1, s2, s\n",
    "\n",
    "# Training and Validation are combined in order to allow for early stopping\n",
    "def train_validate(model, epochs, lr, is_early_stopping=False, is_pca=False, is_sparse=False, patience=None, beta=None, rho=None):\n",
    "    # Define Adam optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Binary Cross Entropy Loss\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Reset model state if previously trained\n",
    "    torch.manual_seed(1)\n",
    "    def weights_init(m):\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            print(\"existing instance\")\n",
    "\n",
    "    model.apply(weights_init)\n",
    "\n",
    "    # Toggle Early Stopping (if using).\n",
    "    if is_early_stopping:\n",
    "        early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "        print(\"Using Early Stopping\")\n",
    "    if is_pca:\n",
    "        print(\"Using PCA\")\n",
    "\n",
    "    print(\"Training...\")\n",
    "\n",
    "    kl_divergence_trace = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #############################    \n",
    "        #          TRAINING         #\n",
    "        #############################\n",
    "        \n",
    "        loss = 0\n",
    "        # Prepare model for training\n",
    "        model.eval()\n",
    "        train_losses = []\n",
    "        for i, batch in enumerate(train_loader, 0):\n",
    "            print(f'batch {i}')\n",
    "\n",
    "            # reshape mini-batch data from [batch_size, 30, 30] to [batch_size, 900]\n",
    "            # load it to the active device\n",
    "            batch = batch\n",
    "            batch = batch.view(-1, n_features).to(device)\n",
    "\n",
    "            # reset the gradients back to zero\n",
    "            # PyTorch accumulates gradients on subsequent backward passes\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute reconstructions\n",
    "            # also retrieve bottleneck weights for computing sparsity penalty\n",
    "\n",
    "            bottleneck, decoded = model(batch)\n",
    "            # try:\n",
    "            #     bottleneck, decoded = model(batch)\n",
    "            #     if torch.all(decoded > 1):\n",
    "            #         raise ExceededRangeError\n",
    "            #     elif torch.all(decoded < 0):\n",
    "            #         raise ExceededRangeError\n",
    "            # except ExceededRangeError:\n",
    "            #     print(\"Values found outside value range in reconstructions (range should be [0.0, 1.0]\")\n",
    "            #     print(decoded)\n",
    "\n",
    "            # Exception handler for when BCE loss has negative values\n",
    "            try:\n",
    "                # compute training reconstruction loss\n",
    "                train_loss = criterion(decoded, batch)\n",
    "            except RuntimeError:\n",
    "                print('Runtime Error during loss calculation')\n",
    "                print('KL Divergence Trace:')\n",
    "                for term in kl_divergence_trace:\n",
    "                    print(term)\n",
    "                for k, sample in enumerate(decoded):\n",
    "                    print(k)\n",
    "                    print(sample)\n",
    "                    # if torch.all(sample < 0):\n",
    "                    #     print(f'{k} has negative')\n",
    "                    #     print(sample)\n",
    "                    # if torch.all(sample > 1):\n",
    "                    #     print(f'{k} has > 1')\n",
    "                    #     print(sample)\n",
    "\n",
    "            #     if train_loss.item() < 0:\n",
    "            #         raise ExceededRangeError\n",
    "            # except ExceededRangeError:\n",
    "            #     print(\"Values found outside value range in BCE loss (range should be [0.0, 1.0]\")\n",
    "            #     print(i)\n",
    "            #     print(outputs)\n",
    "            #     print(batch)\n",
    "            \n",
    "            # add sparsity penalty, if toggled\n",
    "            if is_sparse:\n",
    "                rho_hat = torch.sum(bottleneck, dim=0, keepdim=True)\n",
    "                # print(bottleneck.size())\n",
    "                # print(bottleneck)\n",
    "                # print(rho_hat)\n",
    "                p, q, s1, s2, s = kl_divergence(rho, rho_hat)\n",
    "                kl_divergence_trace = [p, q, s1, s2, s]\n",
    "                sparsity_penalty = beta * s\n",
    "                train_loss = train_loss + sparsity_penalty\n",
    "\n",
    "            # compute accumulated gradients\n",
    "            train_loss.backward()\n",
    "\n",
    "            # perform parameter update based on current gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # add the mini-batch training loss to epoch loss\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "        # compute the epoch training loss\n",
    "        avg_train_loss = np.average(train_losses)\n",
    "\n",
    "        #############################    \n",
    "        #         VALIDATION        #\n",
    "        #############################\n",
    "\n",
    "        # Decoupled into three lists due to issue with placing torch tensors into multidimensional lists\n",
    "        batches = []\n",
    "        recons = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Prepare model for evaluation\n",
    "        model.eval()\n",
    "\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(val_loader, 0):\n",
    "                batch = batch.view(-1, n_features).to(device)\n",
    "                bottleneck, reconstructions = model(batch)\n",
    "                # Reconstruction loss\n",
    "                val_loss = criterion(reconstructions, batch)\n",
    "                # Store samples, predictions, and loss for visualization purposes\n",
    "                batches.append(batch)\n",
    "                recons.append(reconstructions)\n",
    "                val_losses.append(val_loss.item())\n",
    "                #print(f'Batch {i}: {val_loss.item()}')\n",
    "\n",
    "        avg_val_loss = np.average(val_losses)\n",
    "        \n",
    "        # display the epoch training loss and validation loss\n",
    "        print(\"Epoch : {}/{}, Training Loss = {:.6f}, Validation Loss = {:.6f}\".format(epoch + 1, epochs, avg_train_loss, avg_val_loss))\n",
    "        \n",
    "        if is_early_stopping:\n",
    "            early_stopping(avg_val_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                opt_epochs = epoch + 1\n",
    "                print(\"Early stopping...\")\n",
    "                # Exit training loop\n",
    "                break\n",
    "    \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    \n",
    "    print(f\"Epochs: {opt_epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}\")\n",
    "    \n",
    "    return  model, avg_train_loss, avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe00d81-b453-42f0-9960-31b097315258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BASIC AUTOENCODER Execute training & validating\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 200\n",
    "# number of hidden units in encoder hidden layer\n",
    "n_units = 50\n",
    "# number of hidden units in latent space\n",
    "latent_units = 4\n",
    "# Boolean for whether to use Early Stopping\n",
    "is_early_stopping = False\n",
    "# early stopping patience; how long to wait after last time validation loss improved.\n",
    "patience = 20\n",
    "\n",
    "basic_model = SparseAutoEncoder(input_shape=n_features,\n",
    "                    n_units=n_units,\n",
    "                    latent_units=latent_units\n",
    "                   ).to(device)\n",
    "\n",
    "basic_model, avg_train_loss, avg_val_loss, opt_epochs = train_validate(model=basic_model,\n",
    "                                                                        epochs=epochs,\n",
    "                                                                        lr=lr,\n",
    "                                                                        is_early_stopping=is_early_stopping, \n",
    "                                                                        is_pca=is_pca,\n",
    "                                                                        patience=patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18dd5d37-5fac-4458-a85f-c78519f2d69d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing instance\n",
      "existing instance\n",
      "existing instance\n",
      "existing instance\n",
      "Training...\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "Runtime Error during loss calculation\n",
      "KL Divergence Trace:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtrain_validate\u001b[1;34m(model, epochs, lr, is_early_stopping, is_pca, is_sparse, patience, beta, rho)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# compute training reconstruction loss\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n",
      "File \u001b[1;32mQ:\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "File \u001b[1;32mQ:\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\nn\\modules\\loss.py:613\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, Tensor)\n\u001b[1;32m--> 613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mQ:\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\nn\\functional.py:2762\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2760\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 2762\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m rho_tensor \u001b[38;5;241m=\u001b[39m rho_tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m sparse_model \u001b[38;5;241m=\u001b[39m SparseAutoEncoder(input_shape\u001b[38;5;241m=\u001b[39mn_features,\n\u001b[0;32m     17\u001b[0m                     n_units\u001b[38;5;241m=\u001b[39mn_units,\n\u001b[0;32m     18\u001b[0m                     latent_units\u001b[38;5;241m=\u001b[39mlatent_units\n\u001b[0;32m     19\u001b[0m                    )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 22\u001b[0m sparse_model, avg_train_loss, avg_val_loss, opt_epochs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mis_early_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_early_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mis_pca\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_pca\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mis_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mrho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrho_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtrain_validate\u001b[1;34m(model, epochs, lr, is_early_stopping, is_pca, is_sparse, patience, beta, rho)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKL Divergence Trace:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m kl_divergence_trace:\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mterm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(decoded):\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(k)\n",
      "File \u001b[1;32mQ:\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\tensor.py:193\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mQ:\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\_tensor_str.py:383\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_str\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 383\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mQ:\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\_tensor_str.py:358\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    357\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 358\u001b[0m                 tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    361\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32mQ:\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\_tensor_str.py:242\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32mQ:\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\_tensor_str.py:90\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(tensor_view, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m tensor_view\u001b[38;5;241m.\u001b[39mne(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# SPARSE AUTOENCODER Execute training & validating\n",
    "lr = 1e-3\n",
    "epochs = 200\n",
    "n_units = 50\n",
    "latent_units = 10\n",
    "is_early_stopping = False\n",
    "# early stopping patience; how long to wait after last time validation loss improved.\n",
    "patience = 20\n",
    "\n",
    "is_sparse = True\n",
    "beta = 1\n",
    "rho = 0.05\n",
    "rho_tensor = torch.FloatTensor([rho for _ in range(latent_units)]).unsqueeze(0)\n",
    "rho_tensor = rho_tensor.to(device)\n",
    "\n",
    "sparse_model = SparseAutoEncoder(input_shape=n_features,\n",
    "                    n_units=n_units,\n",
    "                    latent_units=latent_units\n",
    "                   ).to(device)\n",
    "\n",
    "\n",
    "sparse_model, avg_train_loss, avg_val_loss, opt_epochs = train_validate(model=sparse_model,\n",
    "                                                    epochs=epochs,\n",
    "                                                    lr=lr,\n",
    "                                                    is_early_stopping=is_early_stopping, \n",
    "                                                    is_pca=is_pca,\n",
    "                                                    is_sparse=is_sparse,\n",
    "                                                    patience=patience,\n",
    "                                                    beta=beta,\n",
    "                                                    rho=rho_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8f6fc-ac70-4663-b8d6-7699cd49e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './cifar_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ff135-bccb-4e15-938f-98ceaf60be72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe1f245-02ab-4956-86ad-913ebcaec715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "# Decoupled into three lists due to issue with placing torch tensors into multidimensional lists\n",
    "batches = []\n",
    "recons = []\n",
    "test_losses = []\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    i = 1\n",
    "    for batch in test_loader:\n",
    "        batch = batch.view(-1, n_features).to(device)\n",
    "        reconstructions = model(batch)\n",
    "        # Reconstruction loss\n",
    "        test_loss = criterion(reconstructions, batch)\n",
    "        # Store samples, predictions, and loss for visualization purposes\n",
    "        batches.append(batch)\n",
    "        recons.append(reconstructions)\n",
    "        test_losses.append(test_loss)\n",
    "        print(f'Batch {i}: {test_loss.item()}')\n",
    "        i += 1\n",
    "\n",
    "test_loss_avg = sum(test_losses) / len(test_losses)\n",
    "print(f\"Average Test Reconstruction Loss: {test_loss_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a0797b-b169-4534-a8cb-bf679aad6a30",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411133d1-7a8f-4acf-9c70-3fb090cef252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "for i in range(len(recons)):\n",
    "    loss = test_losses[i]\n",
    "    batch = batches[i]\n",
    "    reconstructions = recons[i]\n",
    "    # Iterate through all examples in ith batch\n",
    "    for j in range(len(batch)):\n",
    "        # Reshape original example for plotting back into 30x30\n",
    "        # or keep as vector of components if using PCA.\n",
    "        if is_pca:\n",
    "            original = batch[j].reshape(1, n_features)\n",
    "        else:\n",
    "            original = batch[j].reshape(data.shape[1], data.shape[2])\n",
    "        original = original.cpu()\n",
    "        # Reshape reconstructed example for plotting\n",
    "        # or keep as vector of components if using PCA.\n",
    "        if is_pca:\n",
    "            reconstruction = reconstructions[j].reshape(1, n_features)\n",
    "        else:\n",
    "            reconstruction = reconstructions[j].reshape(data.shape[1], data.shape[2])\n",
    "        reconstruction = reconstruction.cpu()\n",
    "        \n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.title(\"Batch : {}/{}, Batch Reconstruction Loss = {:.6f}\".format(i+1, len(recons), loss))\n",
    "        plt.axis('off')\n",
    "        # display original\n",
    "        fig.add_subplot(1, 2, 1)\n",
    "        plt.imshow(original)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"original\")\n",
    "        plt.gray()\n",
    "        \n",
    "        # fig.get_xaxis().set_visible(False)\n",
    "        # fig.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        fig.add_subplot(1, 2, 2)\n",
    "        plt.imshow(reconstruction)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"reconstructed\")\n",
    "        plt.gray()\n",
    "        # fig.get_xaxis().set_visible(False)\n",
    "        # fig.get_yaxis().set_visible(False)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bigan] *",
   "language": "python",
   "name": "conda-env-bigan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
