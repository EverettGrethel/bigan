{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c44b4cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495aef96-9947-4968-a7ac-177f81a83dd0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..\\early-stopping-pytorch')\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70724590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.input_shape = kwargs[\"input_shape\"]\n",
    "        # number of hidden units in first hidden layer\n",
    "        self.n_units = kwargs[\"n_units\"]\n",
    "        self.latent_units = kwargs[\"latent_units\"]\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            # Linear(): Initiate a linear function theta*x + b\n",
    "            nn.Linear(in_features=self.input_shape, out_features=self.n_units),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Linear(in_features=self.n_units, out_features=self.latent_units),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            nn.Linear(in_features=self.latent_units, out_features=self.n_units),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Linear(in_features=self.n_units, out_features=self.input_shape),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    # X denotes features\n",
    "    def forward(self, X):\n",
    "        encode = self.encoder(X)\n",
    "        decode = self.decoder(encode)\n",
    "        return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dca68d50-8eeb-4d3a-8150-f5508bdf9d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data.\n"
     ]
    }
   ],
   "source": [
    "# 10,000 samples, 30x30 matrices\n",
    "is_pca = False\n",
    "data = np.ndarray(shape=(10000,30,30))\n",
    "n_features = data.shape[1] * data.shape[2]\n",
    "\n",
    "for i in range(10000):\n",
    "    path = f'data/jet_matrices/sample{i+1}.dat'\n",
    "    sample = np.loadtxt(path, unpack = True)\n",
    "    data[i] = sample\n",
    "\n",
    "print(\"Done loading data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8891f7fc-06ec-4a54-9e54-3189e67da3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Flatten data and convert to Torch Tensor\n",
    "\n",
    "# 10,000 samples, 900 features\n",
    "X = np.ndarray(shape=(10000, n_features))\n",
    "for i, sample in enumerate(data):\n",
    "    flat = sample.flatten()\n",
    "    X[i] = flat\n",
    "    #print(X[i])\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "# Convert all scalars to floats. May affect training behavior (ie. reconstructions made of non-binary scalar values)\n",
    "X = X.float()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40435a6-d2d2-4a67-8b9d-a4ceeabda9f9",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38354ca1-cb26-48dc-ad4b-73c616477bde",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def de_correlate_data(X):\n",
    "    X_pert = np.copy(X)\n",
    "    i = 0\n",
    "    for col in X.T:\n",
    "        #print(col)\n",
    "        X_pert[:,i] = np.random.permutation(col)\n",
    "        #print(X_pert[:,i])\n",
    "        i += 1\n",
    "        \n",
    "    return X_pert\n",
    "\n",
    "# # function demo\n",
    "# z = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "# #z = np.array([[0,1,0],[1,0,1],[1,1,1]])\n",
    "# print(z)\n",
    "# X_pert = de_correlate_data(z)\n",
    "# print(X_pert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d2f802-706f-4e61-b59a-1b5a7c5c11c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot cumulative explained variance w.r.t. number of components\n",
    "\n",
    "def pca_run(X):\n",
    "    pca = PCA(n_components=0.95).fit(X)\n",
    "\n",
    "    #% matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    y = np.cumsum(pca.explained_variance_ratio_)\n",
    "    # n_components = number of components needed to reach cum. variance threshold\n",
    "    n_components = y.size\n",
    "    xi = np.arange(1, n_components+1, step=1)\n",
    "\n",
    "    plt.ylim(0.0,1.1)\n",
    "    plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
    "\n",
    "    plt.xlabel('Number of Components')\n",
    "    #change from 0-based array index to 1-based human-readable label\n",
    "    plt.xticks(np.arange(0, n_components+1, step=1))\n",
    "    plt.ylabel('Cumulative variance (%)')\n",
    "    plt.title('The Number of Components Needed to Explain Variance')\n",
    "\n",
    "    plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "    plt.axhline(y=0.8, color='g', linestyle='-')\n",
    "    plt.axhline(y=0.9, color='b', linestyle='-')\n",
    "    plt.text(0, 0.915, '95% cut-off threshold', color = 'red', fontsize=13)\n",
    "    plt.text(24, 0.85, '90% cut-off threshold', color = 'blue', fontsize=13)\n",
    "    plt.text(12, 0.75, '80% cut-off threshold', color = 'green', fontsize=13)\n",
    "\n",
    "    ax.grid(axis='x')\n",
    "    plt.show()\n",
    "\n",
    "# Run with original data.\n",
    "pca_run(X.numpy())\n",
    "\n",
    "# Run with permutated data.\n",
    "# De-correlates features, so performing worse than original data indicates\n",
    "# existence of correlation in the original data's features.\n",
    "X_pert = de_correlate_data(X)\n",
    "pca_run(X_pert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75306b-57ab-407a-bb35-d7f160e75c5b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(xi, pca.explained_variance_ratio_, width=0.4)\n",
    "plt.ylabel(\"Percent of Total Variance\")\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.title(\"Significance of Each Principal Component Towards Variance \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96362bf4-42d8-49b8-a6fa-aeb5a8359ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "\n",
    "# Toggle to indicate to training that PCA is in use\n",
    "is_pca = True\n",
    "# -- DEFINE NUMBER OF COMPONENTS HERE --\n",
    "n_components = 5\n",
    "\n",
    "pca = PCA(n_components=n_components).fit(X.numpy())\n",
    "\n",
    "print(X)\n",
    "# If fails, re-run \"Flatten data...\" cell\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca = torch.from_numpy(X_pca)\n",
    "# Convert all scalars to floats. May affect training behavior (ie. reconstructions made of non-binary scalar values)\n",
    "X_pca = X_pca.float()\n",
    "# Replace former n_features with number of components\n",
    "n_features = X_pca.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8875d4ed-f4c5-4bf5-878e-ccb76d4645d7",
   "metadata": {},
   "source": [
    "## Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cc40b83a-dcd0-457f-9b37-0261177fb051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# Changes X based on whether PCA was used\n",
    "if is_pca:\n",
    "    X_2 = X_pca\n",
    "else:\n",
    "    X_2 = X\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "train_size = int(0.8 * len(X_2))\n",
    "val_size = len(X_2) - train_size\n",
    "# AutoEncoder number of hidden units in encoder hidden layer\n",
    "n_units = 50\n",
    "# AutoEncoder number of hidden units in decoder hidden layer\n",
    "# (ie. the maximum dimensionality of latent space)\n",
    "latent_units = 4\n",
    "# Boolean for whether to use Early Stopping\n",
    "is_early_stopping = True\n",
    "# early stopping patience; how long to wait after last time validation loss improved.\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6d9f72fd-043f-4203-ba7e-3098c76b6a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Initate data loaders\n",
    "\n",
    "train, val = torch.utils.data.random_split(X_2, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "# Use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f43042c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # USE FOR MNIST ONLY\n",
    "\n",
    "# input_shape = 784\n",
    "# # Convert numpy array to tensor\n",
    "# transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# # Define \n",
    "# train = torchvision.datasets.MNIST(\n",
    "#     root=\"~/torch_datasets\", train=True, transform=transform, download=True\n",
    "# )\n",
    "\n",
    "# test = torchvision.datasets.MNIST(\n",
    "#     root=\"~/torch_datasets\", train=False, transform=transform, download=True\n",
    "# )\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    "# )\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     test, batch_size=batch_size, shuffle=False, num_workers=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e006349d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############################    \n",
    "#   TRAINING & VALIDATION   #\n",
    "#############################\n",
    "\n",
    "def kl_divergence(rho, rho_hat):\n",
    "    # sigmoid because we need the probability distributions\n",
    "    rho_hat = torch.mean(F.sigmoid(rho_hat), 1)\n",
    "    rho = torch.tensor([rho] * len(rho_hat)).to(device)\n",
    "    return torch.sum(rho * torch.log(rho/rho_hat) + (1 - rho) * torch.log((1 - rho)/(1 - rho_hat)))\n",
    "\n",
    "def sparse_loss(rho, data):\n",
    "    values = data\n",
    "    loss = 0\n",
    "    # get the layers as a list\n",
    "    model_children = list(model.children())\n",
    "    print(model_children)\n",
    "    \n",
    "    # forward-propagate batch across the network\n",
    "    for i in range(len(model_children)):\n",
    "        # forward-propagate to next layer\n",
    "        values = model_children[i](values)\n",
    "        print(\"values\")\n",
    "        print(values.shape)\n",
    "        # then calculate KL Divergence for layer\n",
    "        \n",
    "        #loss += kl_divergence(rho, values)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Training and Validation are combined in order to allow for early stopping\n",
    "def train_validate(epochs, lr, is_early_stopping=False, is_pca=False, is_sparse=False, patience=None, beta=None, rho=None):\n",
    "    # Define Adam optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Binary Cross Entropy Loss\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Reset model state if previously trained\n",
    "    torch.manual_seed(1)\n",
    "    def weights_init(m):\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            print(\"existing instance\")\n",
    "\n",
    "    model.apply(weights_init)\n",
    "\n",
    "    # Toggle Early Stopping (if using).\n",
    "    if is_early_stopping:\n",
    "        early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "        print(\"Using Early Stopping\")\n",
    "    if is_pca:\n",
    "        print(\"Using PCA\")\n",
    "\n",
    "    print(\"Training...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #############################    \n",
    "        #          TRAINING         #\n",
    "        #############################\n",
    "        \n",
    "        loss = 0\n",
    "        # Prepare model for training\n",
    "        model.eval()\n",
    "        train_losses = []\n",
    "        for i, batch in enumerate(train_loader, 0):\n",
    "\n",
    "            # reshape mini-batch data from [batch_size, 30, 30] to [batch_size, 900]\n",
    "            # load it to the active device\n",
    "            batch = batch\n",
    "            batch = batch.view(-1, n_features).to(device)\n",
    "\n",
    "            # reset the gradients back to zero\n",
    "            # PyTorch accumulates gradients on subsequent backward passes\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute reconstructions\n",
    "            outputs = model(batch)\n",
    "            \n",
    "            # Exception handler for when BCE loss has negative values\n",
    "            try:\n",
    "                # compute training reconstruction loss\n",
    "                train_loss = criterion(outputs, batch)\n",
    "                \n",
    "                if train_loss.item() < 0:\n",
    "                    raise NegativeValueError\n",
    "            except NegativeValueError:\n",
    "                print(\"Negative values found in BCE loss (range should be [0.0, 1.0]\")\n",
    "                print(i)\n",
    "                print(outputs)\n",
    "                print(batch)\n",
    "            \n",
    "            # toggle sparsity loss function\n",
    "            if is_sparse:\n",
    "                sparse_penalty = sparse_loss(model, batch)\n",
    "                # add the sparsity penalty\n",
    "                train_loss = train_loss + beta * sparse_penalty\n",
    "\n",
    "            # compute accumulated gradients\n",
    "            train_loss.backward()\n",
    "\n",
    "            # perform parameter update based on current gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # add the mini-batch training loss to epoch loss\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "        # compute the epoch training loss\n",
    "        avg_train_loss = np.average(train_losses)\n",
    "\n",
    "        #############################    \n",
    "        #         VALIDATION        #\n",
    "        #############################\n",
    "\n",
    "        # Decoupled into three lists due to issue with placing torch tensors into multidimensional lists\n",
    "        batches = []\n",
    "        recons = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Prepare model for evaluation\n",
    "        model.eval()\n",
    "\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(val_loader, 0):\n",
    "                batch = batch.view(-1, n_features).to(device)\n",
    "                reconstructions = model(batch)\n",
    "                # Reconstruction loss\n",
    "                val_loss = criterion(reconstructions, batch)\n",
    "                # Store samples, predictions, and loss for visualization purposes\n",
    "                batches.append(batch)\n",
    "                recons.append(reconstructions)\n",
    "                val_losses.append(val_loss.item())\n",
    "                #print(f'Batch {i}: {val_loss.item()}')\n",
    "\n",
    "        avg_val_loss = np.average(val_losses)\n",
    "        \n",
    "        # display the epoch training loss and validation loss\n",
    "        print(\"Epoch : {}/{}, Training Loss = {:.6f}, Validation Loss = {:.6f}\".format(epoch + 1, epochs, avg_train_loss, avg_val_loss))\n",
    "        \n",
    "        if is_early_stopping:\n",
    "            early_stopping(avg_val_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                opt_epochs = epoch + 1\n",
    "                print(\"Early stopping...\")\n",
    "                # Exit training loop\n",
    "                break\n",
    "    \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    \n",
    "    print(f\"Epochs: {opt_epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}\")\n",
    "    \n",
    "    return  model, avg_train_loss, avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dfe00d81-b453-42f0-9960-31b097315258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing instance\n",
      "existing instance\n",
      "existing instance\n",
      "existing instance\n",
      "Training...\n",
      "Epoch : 1/200, Training Loss = 0.060170, Validation Loss = 0.016783\n",
      "Epoch : 2/200, Training Loss = 0.012319, Validation Loss = 0.010566\n",
      "Epoch : 3/200, Training Loss = 0.010094, Validation Loss = 0.009624\n",
      "Epoch : 4/200, Training Loss = 0.009347, Validation Loss = 0.008912\n",
      "Epoch : 5/200, Training Loss = 0.008429, Validation Loss = 0.008026\n",
      "Epoch : 6/200, Training Loss = 0.007428, Validation Loss = 0.006880\n",
      "Epoch : 7/200, Training Loss = 0.006363, Validation Loss = 0.006006\n",
      "Epoch : 8/200, Training Loss = 0.005670, Validation Loss = 0.005694\n",
      "Epoch : 9/200, Training Loss = 0.005197, Validation Loss = 0.004961\n",
      "Epoch : 10/200, Training Loss = 0.004941, Validation Loss = 0.004838\n",
      "Epoch : 11/200, Training Loss = 0.004612, Validation Loss = 0.004625\n",
      "Epoch : 12/200, Training Loss = 0.004376, Validation Loss = 0.004723\n",
      "Epoch : 13/200, Training Loss = 0.004130, Validation Loss = 0.004291\n",
      "Epoch : 14/200, Training Loss = 0.004037, Validation Loss = 0.004633\n",
      "Epoch : 15/200, Training Loss = 0.003951, Validation Loss = 0.004072\n",
      "Epoch : 16/200, Training Loss = 0.003771, Validation Loss = 0.004192\n",
      "Epoch : 17/200, Training Loss = 0.003616, Validation Loss = 0.003787\n",
      "Epoch : 18/200, Training Loss = 0.003793, Validation Loss = 0.003947\n",
      "Epoch : 19/200, Training Loss = 0.003402, Validation Loss = 0.003494\n",
      "Epoch : 20/200, Training Loss = 0.003397, Validation Loss = 0.003547\n",
      "Epoch : 21/200, Training Loss = 0.003442, Validation Loss = 0.003442\n",
      "Epoch : 22/200, Training Loss = 0.003195, Validation Loss = 0.003575\n",
      "Epoch : 23/200, Training Loss = 0.003266, Validation Loss = 0.003619\n",
      "Epoch : 24/200, Training Loss = 0.003205, Validation Loss = 0.003489\n",
      "Epoch : 25/200, Training Loss = 0.003102, Validation Loss = 0.003359\n",
      "Epoch : 26/200, Training Loss = 0.003016, Validation Loss = 0.003244\n",
      "Epoch : 27/200, Training Loss = 0.003279, Validation Loss = 0.003158\n",
      "Epoch : 28/200, Training Loss = 0.002847, Validation Loss = 0.003146\n",
      "Epoch : 29/200, Training Loss = 0.002928, Validation Loss = 0.003189\n",
      "Epoch : 30/200, Training Loss = 0.002798, Validation Loss = 0.003379\n",
      "Epoch : 31/200, Training Loss = 0.002808, Validation Loss = 0.003221\n",
      "Epoch : 32/200, Training Loss = 0.002707, Validation Loss = 0.003243\n",
      "Epoch : 33/200, Training Loss = 0.002718, Validation Loss = 0.003317\n",
      "Epoch : 34/200, Training Loss = 0.002657, Validation Loss = 0.003253\n",
      "Epoch : 35/200, Training Loss = 0.002808, Validation Loss = 0.003124\n",
      "Epoch : 36/200, Training Loss = 0.002747, Validation Loss = 0.003382\n",
      "Epoch : 37/200, Training Loss = 0.002501, Validation Loss = 0.002840\n",
      "Epoch : 38/200, Training Loss = 0.002650, Validation Loss = 0.003531\n",
      "Epoch : 39/200, Training Loss = 0.002776, Validation Loss = 0.003094\n",
      "Epoch : 40/200, Training Loss = 0.002598, Validation Loss = 0.003182\n",
      "Epoch : 41/200, Training Loss = 0.002406, Validation Loss = 0.002947\n",
      "Epoch : 42/200, Training Loss = 0.002495, Validation Loss = 0.002889\n",
      "Epoch : 43/200, Training Loss = 0.002413, Validation Loss = 0.004213\n",
      "Epoch : 44/200, Training Loss = 0.002366, Validation Loss = 0.003242\n",
      "Epoch : 45/200, Training Loss = 0.002469, Validation Loss = 0.003750\n",
      "Epoch : 46/200, Training Loss = 0.002455, Validation Loss = 0.003393\n",
      "Epoch : 47/200, Training Loss = 0.002397, Validation Loss = 0.003169\n",
      "Epoch : 48/200, Training Loss = 0.002320, Validation Loss = 0.003365\n",
      "Epoch : 49/200, Training Loss = 0.002326, Validation Loss = 0.002947\n",
      "Epoch : 50/200, Training Loss = 0.002565, Validation Loss = 0.003048\n",
      "Epoch : 51/200, Training Loss = 0.002297, Validation Loss = 0.002770\n",
      "Epoch : 52/200, Training Loss = 0.002250, Validation Loss = 0.002780\n",
      "Epoch : 53/200, Training Loss = 0.002230, Validation Loss = 0.003437\n",
      "Epoch : 54/200, Training Loss = 0.002233, Validation Loss = 0.002715\n",
      "Epoch : 55/200, Training Loss = 0.002087, Validation Loss = 0.002825\n",
      "Epoch : 56/200, Training Loss = 0.002520, Validation Loss = 0.004593\n",
      "Epoch : 57/200, Training Loss = 0.002220, Validation Loss = 0.002766\n",
      "Epoch : 58/200, Training Loss = 0.002112, Validation Loss = 0.002774\n",
      "Epoch : 59/200, Training Loss = 0.002147, Validation Loss = 0.003320\n",
      "Epoch : 60/200, Training Loss = 0.002110, Validation Loss = 0.002740\n",
      "Epoch : 61/200, Training Loss = 0.002027, Validation Loss = 0.003307\n",
      "Epoch : 62/200, Training Loss = 0.002391, Validation Loss = 0.010985\n",
      "Epoch : 63/200, Training Loss = 0.003217, Validation Loss = 0.002641\n",
      "Epoch : 64/200, Training Loss = 0.001839, Validation Loss = 0.002613\n",
      "Epoch : 65/200, Training Loss = 0.001822, Validation Loss = 0.002615\n",
      "Epoch : 66/200, Training Loss = 0.001920, Validation Loss = 0.002796\n",
      "Epoch : 67/200, Training Loss = 0.001843, Validation Loss = 0.002715\n",
      "Epoch : 68/200, Training Loss = 0.001915, Validation Loss = 0.002899\n",
      "Epoch : 69/200, Training Loss = 0.001955, Validation Loss = 0.002808\n",
      "Epoch : 70/200, Training Loss = 0.002188, Validation Loss = 0.002997\n",
      "Epoch : 71/200, Training Loss = 0.001874, Validation Loss = 0.002570\n",
      "Epoch : 72/200, Training Loss = 0.001791, Validation Loss = 0.002731\n",
      "Epoch : 73/200, Training Loss = 0.002742, Validation Loss = 0.003340\n",
      "Epoch : 74/200, Training Loss = 0.001763, Validation Loss = 0.002570\n",
      "Epoch : 75/200, Training Loss = 0.001699, Validation Loss = 0.002874\n",
      "Epoch : 76/200, Training Loss = 0.001695, Validation Loss = 0.002440\n",
      "Epoch : 77/200, Training Loss = 0.001737, Validation Loss = 0.002611\n",
      "Epoch : 78/200, Training Loss = 0.001843, Validation Loss = 0.003176\n",
      "Epoch : 79/200, Training Loss = 0.002152, Validation Loss = 0.003057\n",
      "Epoch : 80/200, Training Loss = 0.001619, Validation Loss = 0.002615\n",
      "Epoch : 81/200, Training Loss = 0.001764, Validation Loss = 0.003199\n",
      "Epoch : 82/200, Training Loss = 0.001813, Validation Loss = 0.002771\n",
      "Epoch : 83/200, Training Loss = 0.001638, Validation Loss = 0.002399\n",
      "Epoch : 84/200, Training Loss = 0.001697, Validation Loss = 0.002586\n",
      "Epoch : 85/200, Training Loss = 0.001588, Validation Loss = 0.002696\n",
      "Epoch : 86/200, Training Loss = 0.001695, Validation Loss = 0.002787\n",
      "Epoch : 87/200, Training Loss = 0.001751, Validation Loss = 0.002476\n",
      "Epoch : 88/200, Training Loss = 0.001718, Validation Loss = 0.002993\n",
      "Epoch : 89/200, Training Loss = 0.001679, Validation Loss = 0.003134\n",
      "Epoch : 90/200, Training Loss = 0.001631, Validation Loss = 0.002714\n",
      "Epoch : 91/200, Training Loss = 0.001589, Validation Loss = 0.002902\n",
      "Epoch : 92/200, Training Loss = 0.001638, Validation Loss = 0.002681\n",
      "Epoch : 93/200, Training Loss = 0.001702, Validation Loss = 0.002353\n",
      "Epoch : 94/200, Training Loss = 0.001463, Validation Loss = 0.002376\n",
      "Epoch : 95/200, Training Loss = 0.001536, Validation Loss = 0.002990\n",
      "Epoch : 96/200, Training Loss = 0.001573, Validation Loss = 0.002381\n",
      "Epoch : 97/200, Training Loss = 0.001545, Validation Loss = 0.002722\n",
      "Epoch : 98/200, Training Loss = 0.001419, Validation Loss = 0.002483\n",
      "Epoch : 99/200, Training Loss = 0.001404, Validation Loss = 0.002432\n",
      "Epoch : 100/200, Training Loss = 0.001594, Validation Loss = 0.002674\n",
      "Epoch : 101/200, Training Loss = 0.001435, Validation Loss = 0.003005\n",
      "Epoch : 102/200, Training Loss = 0.001575, Validation Loss = 0.002820\n",
      "Epoch : 103/200, Training Loss = 0.001427, Validation Loss = 0.002480\n",
      "Epoch : 104/200, Training Loss = 0.001429, Validation Loss = 0.002963\n",
      "Epoch : 105/200, Training Loss = 0.001388, Validation Loss = 0.002479\n",
      "Epoch : 106/200, Training Loss = 0.002096, Validation Loss = 0.002312\n",
      "Epoch : 107/200, Training Loss = 0.001225, Validation Loss = 0.002367\n",
      "Epoch : 108/200, Training Loss = 0.001350, Validation Loss = 0.002387\n",
      "Epoch : 109/200, Training Loss = 0.001286, Validation Loss = 0.002577\n",
      "Epoch : 110/200, Training Loss = 0.001386, Validation Loss = 0.002364\n",
      "Epoch : 111/200, Training Loss = 0.001382, Validation Loss = 0.003119\n",
      "Epoch : 112/200, Training Loss = 0.001404, Validation Loss = 0.002589\n",
      "Epoch : 113/200, Training Loss = 0.001499, Validation Loss = 0.003060\n",
      "Epoch : 114/200, Training Loss = 0.001382, Validation Loss = 0.002400\n",
      "Epoch : 115/200, Training Loss = 0.001274, Validation Loss = 0.002617\n",
      "Epoch : 116/200, Training Loss = 0.001345, Validation Loss = 0.004035\n",
      "Epoch : 117/200, Training Loss = 0.001682, Validation Loss = 0.002760\n",
      "Epoch : 118/200, Training Loss = 0.001252, Validation Loss = 0.002452\n",
      "Epoch : 119/200, Training Loss = 0.001196, Validation Loss = 0.002524\n",
      "Epoch : 120/200, Training Loss = 0.001216, Validation Loss = 0.002489\n",
      "Epoch : 121/200, Training Loss = 0.001353, Validation Loss = 0.002221\n",
      "Epoch : 122/200, Training Loss = 0.001325, Validation Loss = 0.002670\n",
      "Epoch : 123/200, Training Loss = 0.001308, Validation Loss = 0.002442\n",
      "Epoch : 124/200, Training Loss = 0.001160, Validation Loss = 0.002751\n",
      "Epoch : 125/200, Training Loss = 0.001358, Validation Loss = 0.002509\n",
      "Epoch : 126/200, Training Loss = 0.001385, Validation Loss = 0.002467\n",
      "Epoch : 127/200, Training Loss = 0.001114, Validation Loss = 0.002322\n",
      "Epoch : 128/200, Training Loss = 0.001271, Validation Loss = 0.002688\n",
      "Epoch : 129/200, Training Loss = 0.001312, Validation Loss = 0.002478\n",
      "Epoch : 130/200, Training Loss = 0.001179, Validation Loss = 0.002502\n",
      "Epoch : 131/200, Training Loss = 0.001285, Validation Loss = 0.002538\n",
      "Epoch : 132/200, Training Loss = 0.001263, Validation Loss = 0.002587\n",
      "Epoch : 133/200, Training Loss = 0.001195, Validation Loss = 0.002361\n",
      "Epoch : 134/200, Training Loss = 0.001202, Validation Loss = 0.002402\n",
      "Epoch : 135/200, Training Loss = 0.001353, Validation Loss = 0.003158\n",
      "Epoch : 136/200, Training Loss = 0.001112, Validation Loss = 0.002528\n",
      "Epoch : 137/200, Training Loss = 0.001153, Validation Loss = 0.002434\n",
      "Epoch : 138/200, Training Loss = 0.001733, Validation Loss = 0.002584\n",
      "Epoch : 139/200, Training Loss = 0.001081, Validation Loss = 0.002414\n",
      "Epoch : 140/200, Training Loss = 0.001070, Validation Loss = 0.002544\n",
      "Epoch : 141/200, Training Loss = 0.001214, Validation Loss = 0.002578\n",
      "Epoch : 142/200, Training Loss = 0.001137, Validation Loss = 0.002503\n",
      "Epoch : 143/200, Training Loss = 0.001200, Validation Loss = 0.002954\n",
      "Epoch : 144/200, Training Loss = 0.001141, Validation Loss = 0.002359\n",
      "Epoch : 145/200, Training Loss = 0.001154, Validation Loss = 0.002643\n",
      "Epoch : 146/200, Training Loss = 0.001182, Validation Loss = 0.003383\n",
      "Epoch : 147/200, Training Loss = 0.001150, Validation Loss = 0.002628\n",
      "Epoch : 148/200, Training Loss = 0.001170, Validation Loss = 0.002769\n",
      "Epoch : 149/200, Training Loss = 0.001076, Validation Loss = 0.002616\n",
      "Epoch : 150/200, Training Loss = 0.001163, Validation Loss = 0.003249\n",
      "Epoch : 151/200, Training Loss = 0.001135, Validation Loss = 0.002373\n",
      "Epoch : 152/200, Training Loss = 0.001217, Validation Loss = 0.003038\n",
      "Epoch : 153/200, Training Loss = 0.001011, Validation Loss = 0.002664\n",
      "Epoch : 154/200, Training Loss = 0.001149, Validation Loss = 0.002785\n",
      "Epoch : 155/200, Training Loss = 0.001094, Validation Loss = 0.004077\n",
      "Epoch : 156/200, Training Loss = 0.001286, Validation Loss = 0.002444\n",
      "Epoch : 157/200, Training Loss = 0.001047, Validation Loss = 0.002812\n",
      "Epoch : 158/200, Training Loss = 0.001090, Validation Loss = 0.003124\n",
      "Epoch : 159/200, Training Loss = 0.001295, Validation Loss = 0.002513\n",
      "Epoch : 160/200, Training Loss = 0.001188, Validation Loss = 0.002566\n",
      "Epoch : 161/200, Training Loss = 0.000974, Validation Loss = 0.002392\n",
      "Epoch : 162/200, Training Loss = 0.001078, Validation Loss = 0.002366\n",
      "Epoch : 163/200, Training Loss = 0.001248, Validation Loss = 0.002553\n",
      "Epoch : 164/200, Training Loss = 0.000888, Validation Loss = 0.002366\n",
      "Epoch : 165/200, Training Loss = 0.000945, Validation Loss = 0.002396\n",
      "Epoch : 166/200, Training Loss = 0.000963, Validation Loss = 0.002748\n",
      "Epoch : 167/200, Training Loss = 0.001336, Validation Loss = 0.002963\n",
      "Epoch : 168/200, Training Loss = 0.001078, Validation Loss = 0.002269\n",
      "Epoch : 169/200, Training Loss = 0.000959, Validation Loss = 0.002470\n",
      "Epoch : 170/200, Training Loss = 0.000974, Validation Loss = 0.002528\n",
      "Epoch : 171/200, Training Loss = 0.001208, Validation Loss = 0.002745\n",
      "Epoch : 172/200, Training Loss = 0.001070, Validation Loss = 0.002725\n",
      "Epoch : 173/200, Training Loss = 0.001044, Validation Loss = 0.002580\n",
      "Epoch : 174/200, Training Loss = 0.001309, Validation Loss = 0.004197\n",
      "Epoch : 175/200, Training Loss = 0.000980, Validation Loss = 0.002197\n",
      "Epoch : 176/200, Training Loss = 0.000874, Validation Loss = 0.002553\n",
      "Epoch : 177/200, Training Loss = 0.000949, Validation Loss = 0.002443\n",
      "Epoch : 178/200, Training Loss = 0.000976, Validation Loss = 0.002361\n",
      "Epoch : 179/200, Training Loss = 0.000989, Validation Loss = 0.002616\n",
      "Epoch : 180/200, Training Loss = 0.001195, Validation Loss = 0.002452\n",
      "Epoch : 181/200, Training Loss = 0.000902, Validation Loss = 0.002542\n",
      "Epoch : 182/200, Training Loss = 0.000990, Validation Loss = 0.002381\n",
      "Epoch : 183/200, Training Loss = 0.000919, Validation Loss = 0.002712\n",
      "Epoch : 184/200, Training Loss = 0.000989, Validation Loss = 0.002943\n",
      "Epoch : 185/200, Training Loss = 0.001175, Validation Loss = 0.002489\n",
      "Epoch : 186/200, Training Loss = 0.000845, Validation Loss = 0.002216\n",
      "Epoch : 187/200, Training Loss = 0.001056, Validation Loss = 0.002538\n",
      "Epoch : 188/200, Training Loss = 0.001042, Validation Loss = 0.002726\n",
      "Epoch : 189/200, Training Loss = 0.000933, Validation Loss = 0.002525\n",
      "Epoch : 190/200, Training Loss = 0.000884, Validation Loss = 0.002420\n",
      "Epoch : 191/200, Training Loss = 0.001231, Validation Loss = 0.002487\n",
      "Epoch : 192/200, Training Loss = 0.000828, Validation Loss = 0.002368\n",
      "Epoch : 193/200, Training Loss = 0.000856, Validation Loss = 0.002440\n",
      "Epoch : 194/200, Training Loss = 0.001015, Validation Loss = 0.003587\n",
      "Epoch : 195/200, Training Loss = 0.000898, Validation Loss = 0.002361\n",
      "Epoch : 196/200, Training Loss = 0.000871, Validation Loss = 0.002400\n",
      "Epoch : 197/200, Training Loss = 0.001040, Validation Loss = 0.002650\n",
      "Epoch : 198/200, Training Loss = 0.000825, Validation Loss = 0.002357\n",
      "Epoch : 199/200, Training Loss = 0.001041, Validation Loss = 0.002617\n",
      "Epoch : 200/200, Training Loss = 0.000985, Validation Loss = 0.002506\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'opt_epochs' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-d621c449684d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                    ).to(device)\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m basic_model, avg_train_loss, avg_val_loss, opt_epochs = train_validate(epochs=epochs,\n\u001b[0m\u001b[0;32m      9\u001b[0m                                                     \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                                     \u001b[0mis_early_stopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-148-7dc4323d85e3>\u001b[0m in \u001b[0;36mtrain_validate\u001b[1;34m(epochs, lr, is_early_stopping, is_pca, is_sparse, patience, beta, rho)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'checkpoint.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epochs: {opt_epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mreturn\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_val_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'opt_epochs' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# BASIC AUTOENCODER Execute training & validating\n",
    "\n",
    "basic_model = AutoEncoder(input_shape=n_features,\n",
    "                    n_units=n_units,\n",
    "                    latent_units=latent_units\n",
    "                   ).to(device)\n",
    "\n",
    "basic_model, avg_train_loss, avg_val_loss, opt_epochs = train_validate(epochs=epochs,\n",
    "                                                    lr=lr,\n",
    "                                                    is_early_stopping=False, \n",
    "                                                    is_pca=is_pca,\n",
    "                                                    is_sparse=False,\n",
    "                                                    patience=patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fe4fd274-92ad-449b-915a-2a2ad4a8a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing instance\n",
      "existing instance\n",
      "existing instance\n",
      "existing instance\n",
      "Using Early Stopping\n",
      "Training...\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=900, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=4, bias=True)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=4, out_features=600, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=600, out_features=900, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")]\n",
      "values\n",
      "torch.Size([32, 4])\n",
      "values\n",
      "torch.Size([32, 900])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-51864348493e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                    ).to(device)\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m sparse_model, avg_train_loss, avg_val_loss, opt_epochs = train_validate(epochs,\n\u001b[0m\u001b[0;32m     13\u001b[0m                                                     \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                                     \u001b[0mis_early_stopping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-88-646449cba182>\u001b[0m in \u001b[0;36mtrain_validate\u001b[1;34m(epochs, lr, is_early_stopping, is_pca, is_sparse, patience, beta, rho)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;31m# perform parameter update based on current gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[1;31m# add the mini-batch training loss to epoch loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'betas'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SPARSE AUTOENCODER Execute training & validating\n",
    "\n",
    "is_sparse = True\n",
    "beta = 1\n",
    "rho = 0.05\n",
    "\n",
    "sparse_model = AutoEncoder(input_shape=n_features,\n",
    "                    n_units=n_units,\n",
    "                    latent_units=latent_units\n",
    "                   ).to(device)\n",
    "\n",
    "sparse_model, avg_train_loss, avg_val_loss, opt_epochs = train_validate(epochs=epochs,\n",
    "                                                    lr=lr,\n",
    "                                                    is_early_stopping=is_early_stopping, \n",
    "                                                    is_pca=is_pca,\n",
    "                                                    is_sparse=is_sparse,\n",
    "                                                    patience=patience,\n",
    "                                                    beta=beta,\n",
    "                                                    rho=rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8f6fc-ac70-4663-b8d6-7699cd49e223",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# PATH = './cifar_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ff135-bccb-4e15-938f-98ceaf60be72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abe1f245-02ab-4956-86ad-913ebcaec715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: 0.0010424429783597589\n",
      "Batch 2: 0.0008662481559440494\n",
      "Batch 3: 0.0006447581690736115\n",
      "Batch 4: 0.0014198245480656624\n",
      "Batch 5: 0.0009701848030090332\n",
      "Batch 6: 0.0007065486279316247\n",
      "Batch 7: 0.0012456371914595366\n",
      "Batch 8: 0.001374464831314981\n",
      "Batch 9: 0.0006396484677679837\n",
      "Batch 10: 0.0010645699221640825\n",
      "Batch 11: 0.000992045970633626\n",
      "Batch 12: 0.0007546028937213123\n",
      "Batch 13: 0.0005238947924226522\n",
      "Batch 14: 0.001122398185543716\n",
      "Batch 15: 0.0008277638698928058\n",
      "Batch 16: 0.0009832956129685044\n",
      "Batch 17: 0.001467206864617765\n",
      "Batch 18: 0.0009598342585377395\n",
      "Batch 19: 0.001200599712319672\n",
      "Batch 20: 0.0006337057566270232\n",
      "Batch 21: 0.000950323767028749\n",
      "Batch 22: 0.0010648424504324794\n",
      "Batch 23: 0.0007375125424005091\n",
      "Batch 24: 0.0013370830565690994\n",
      "Batch 25: 0.0006244308315217495\n",
      "Batch 26: 0.0007181363762356341\n",
      "Batch 27: 0.0007808441878296435\n",
      "Batch 28: 0.0009216194739565253\n",
      "Batch 29: 0.0010759844444692135\n",
      "Batch 30: 0.000927358225453645\n",
      "Batch 31: 0.0010030141565948725\n",
      "Batch 32: 0.0008876695646904409\n",
      "Batch 33: 0.0008448354783467948\n",
      "Batch 34: 0.0009363958961330354\n",
      "Batch 35: 0.0006232880987226963\n",
      "Batch 36: 0.0009386669262312353\n",
      "Batch 37: 0.0009169727563858032\n",
      "Batch 38: 0.001072036917321384\n",
      "Batch 39: 0.0010055996244773269\n",
      "Batch 40: 0.0014783748192712665\n",
      "Batch 41: 0.0011764807859435678\n",
      "Batch 42: 0.0011240241583436728\n",
      "Batch 43: 0.0012719734804704785\n",
      "Batch 44: 0.0006919321021996439\n",
      "Batch 45: 0.0009556585573591292\n",
      "Batch 46: 0.0008649253868497908\n",
      "Batch 47: 0.0007208026945590973\n",
      "Batch 48: 0.001220167730934918\n",
      "Batch 49: 0.0007361606694757938\n",
      "Batch 50: 0.001415804959833622\n",
      "Batch 51: 0.0009316194336861372\n",
      "Batch 52: 0.0006900861626490951\n",
      "Batch 53: 0.0006523519405163825\n",
      "Batch 54: 0.0010301597649231553\n",
      "Batch 55: 0.0013595025520771742\n",
      "Batch 56: 0.0006388036417774856\n",
      "Batch 57: 0.0008325903909280896\n",
      "Batch 58: 0.000603143242187798\n",
      "Batch 59: 0.0008613289683125913\n",
      "Batch 60: 0.0009048565989360213\n",
      "Batch 61: 0.0008765614475123584\n",
      "Batch 62: 0.0009015594841912389\n",
      "Batch 63: 0.0005988127668388188\n",
      "Average Test Reconstruction Loss: 0.0009419681155122817\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "# Decoupled into three lists due to issue with placing torch tensors into multidimensional lists\n",
    "batches = []\n",
    "recons = []\n",
    "test_losses = []\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    i = 1\n",
    "    for batch in test_loader:\n",
    "        batch = batch.view(-1, n_features).to(device)\n",
    "        reconstructions = model(batch)\n",
    "        # Reconstruction loss\n",
    "        test_loss = criterion(reconstructions, batch)\n",
    "        # Store samples, predictions, and loss for visualization purposes\n",
    "        batches.append(batch)\n",
    "        recons.append(reconstructions)\n",
    "        test_losses.append(test_loss)\n",
    "        print(f'Batch {i}: {test_loss.item()}')\n",
    "        i += 1\n",
    "\n",
    "test_loss_avg = sum(test_losses) / len(test_losses)\n",
    "print(f\"Average Test Reconstruction Loss: {test_loss_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a0797b-b169-4534-a8cb-bf679aad6a30",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "411133d1-7a8f-4acf-9c70-3fb090cef252",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-50cda6b6076f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# fig.get_xaxis().set_visible(False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# fig.get_yaxis().set_visible(False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \"\"\"\n\u001b[0;32m    367\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_backend_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             display(\n\u001b[0m\u001b[0;32m     41\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2317\u001b[0m                 \u001b[1;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2318\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2319\u001b[1;33m                     result = print_method(\n\u001b[0m\u001b[0;32m   2320\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2321\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1646\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1648\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    410\u001b[0m                          \u001b[1;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 **kwargs)\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[0mDECORATORS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[0;32m    538\u001b[0m             \u001b[1;33m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m         \"\"\"\n\u001b[1;32m--> 540\u001b[1;33m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m         mpl.image.imsave(\n\u001b[0;32m    542\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"upper\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    434\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[0;32m    435\u001b[0m               else nullcontext()):\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m             \u001b[1;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;31m# don't forget to call the superclass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2810\u001b[1;33m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[0;32m   2811\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[0;32m   2812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3080\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[0;32m   3083\u001b[0m             renderer, self, artists, self.figure.suppressComposite)\n\u001b[0;32m   3084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    731\u001b[0m                                           mtext=mtext)\n\u001b[0;32m    732\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m                     textrenderer.draw_text(gc, x, y, clean_line,\n\u001b[0m\u001b[0;32m    734\u001b[0m                                            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m                                            ismath=ismath, mtext=mtext)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigan\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw_text\u001b[1;34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;31m# We pass '0' for angle here, since it will be rotated (in raster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# space) in the following call to draw_text_image).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         font.draw_glyphs_to_bitmap(\n\u001b[0;32m    239\u001b[0m             antialiased=mpl.rcParams['text.antialiased'])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Visualization\n",
    "\n",
    "for i in range(len(recons)):\n",
    "    loss = test_losses[i]\n",
    "    batch = batches[i]\n",
    "    reconstructions = recons[i]\n",
    "    # Iterate through all examples in ith batch\n",
    "    for j in range(len(batch)):\n",
    "        # Reshape original example for plotting back into 30x30\n",
    "        # or keep as vector of components if using PCA.\n",
    "        if is_pca:\n",
    "            original = batch[j].reshape(1, n_features)\n",
    "        else:\n",
    "            original = batch[j].reshape(data.shape[1], data.shape[2])\n",
    "        original = original.cpu()\n",
    "        # Reshape reconstructed example for plotting\n",
    "        # or keep as vector of components if using PCA.\n",
    "        if is_pca:\n",
    "            reconstruction = reconstructions[j].reshape(1, n_features)\n",
    "        else:\n",
    "            reconstruction = reconstructions[j].reshape(data.shape[1], data.shape[2])\n",
    "        reconstruction = reconstruction.cpu()\n",
    "        \n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.title(\"Batch : {}/{}, Batch Reconstruction Loss = {:.6f}\".format(i+1, len(recons), loss))\n",
    "        plt.axis('off')\n",
    "        # display original\n",
    "        fig.add_subplot(1, 2, 1)\n",
    "        plt.imshow(original)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"original\")\n",
    "        plt.gray()\n",
    "        \n",
    "        # fig.get_xaxis().set_visible(False)\n",
    "        # fig.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        fig.add_subplot(1, 2, 2)\n",
    "        plt.imshow(reconstruction)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"reconstructed\")\n",
    "        plt.gray()\n",
    "        # fig.get_xaxis().set_visible(False)\n",
    "        # fig.get_yaxis().set_visible(False)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bigan] *",
   "language": "python",
   "name": "conda-env-bigan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
